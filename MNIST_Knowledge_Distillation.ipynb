{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f657cc1-8b9c-461a-969f-056f7e4d385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Max\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tqdm.notebook import tqdm  # Import the tqdm library for progress bars\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af20469-0c84-45b5-9849-fdb8767e3eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.2295 - accuracy: 0.9315 - val_loss: 0.1217 - val_accuracy: 0.9623\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0940 - accuracy: 0.9700 - val_loss: 0.1051 - val_accuracy: 0.9672\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.0907 - val_accuracy: 0.9725\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.0872 - val_accuracy: 0.9761\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0980 - val_accuracy: 0.9757\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0780 - accuracy: 0.9780\n",
      "Teacher Model Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize the data\n",
    "\n",
    "# Reshape for the models\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Define the teacher model (Small Scale Model)\n",
    "teacher_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the teacher model\n",
    "teacher_model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "teacher_model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the teacher model\n",
    "teacher_accuracy = teacher_model.evaluate(x_test, y_test)[1]\n",
    "print(f\"Teacher Model Accuracy: {teacher_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b830fa16-73f1-48a2-92cd-4c046075127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c839884e914817b51f3df4827cd710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/1500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 1.3733, Training Accuracy: 0.8683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8a6d9967d74d32b454009a911399a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|          | 0/375 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2728, Validation Accuracy: 0.9300\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e66e0b5ce749a8b79d9019fdfdd751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/1500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 1.2537, Training Accuracy: 0.9396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3907345e99df44a28ac7653cd88a8342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|          | 0/375 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2440, Validation Accuracy: 0.9478\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df263db5809d43c897283fb90dc17693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/1500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 1.2305, Training Accuracy: 0.9525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea4f32f356a42bd8673bc09703a95ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|          | 0/375 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2311, Validation Accuracy: 0.9549\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bfbb878b8d4c6ba5e7b521da58b033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/1500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 1.2174, Training Accuracy: 0.9611\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1426aa8ee4ed43a483caca5fa8f498cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|          | 0/375 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2233, Validation Accuracy: 0.9586\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4b6718bda04caa8be2d423259eb450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/1500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Loss: 1.2088, Training Accuracy: 0.9658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c9238422b1410c8547efb65b44e7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|          | 0/375 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2193, Validation Accuracy: 0.9615\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1413 - accuracy: 0.9586\n",
      "Student Model Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Define the student model (Nano Scale Model)\n",
    "student_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Knowledge Distillation Loss Function\n",
    "def distillation_loss(y_true, y_pred, teacher_logits, temperature=5):\n",
    "    # Cross-entropy with soft predictions from the teacher\n",
    "    soft_labels = tf.nn.softmax(teacher_logits / temperature)\n",
    "    student_logits = tf.nn.softmax(y_pred / temperature)\n",
    "    soft_loss = CategoricalCrossentropy()(soft_labels, student_logits)\n",
    "    \n",
    "    # Cross-entropy with ground-truth labels\n",
    "    hard_loss = CategoricalCrossentropy()(y_true, y_pred)\n",
    "    \n",
    "    # Combine the two losses\n",
    "    return 0.5 * soft_loss + 0.5 * hard_loss\n",
    "\n",
    "# Custom Training Loop for Knowledge Distillation\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "temperature = 5  # Temperature for softening probabilities\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare the training and validation datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)\n",
    "\n",
    "\n",
    "# Training loop with progress bar\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss = 0.0\n",
    "    train_steps = 0\n",
    "    train_accuracy_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # Wrap training dataset with tqdm for progress bar\n",
    "    train_dataset_tqdm = tqdm(train_dataset, desc=\"Training Progress\", unit=\"batch\")\n",
    "    for x_batch, y_batch in train_dataset_tqdm:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Teacher predictions\n",
    "            teacher_logits = teacher_model(x_batch, training=False)\n",
    "            \n",
    "            # Student predictions\n",
    "            y_pred = student_model(x_batch, training=True)\n",
    "            \n",
    "            # Compute the distillation loss\n",
    "            loss = distillation_loss(y_batch, y_pred, teacher_logits, temperature)\n",
    "        \n",
    "        # Backpropagation\n",
    "        gradients = tape.gradient(loss, student_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, student_model.trainable_variables))\n",
    "        \n",
    "        # Track training loss and accuracy\n",
    "        train_loss += loss.numpy()\n",
    "        train_accuracy_metric.update_state(y_batch, y_pred)\n",
    "        train_steps += 1\n",
    "        \n",
    "        # Update tqdm description\n",
    "        train_dataset_tqdm.set_postfix(loss=loss.numpy())\n",
    "\n",
    "    avg_train_loss = train_loss / train_steps\n",
    "    train_accuracy = train_accuracy_metric.result().numpy()\n",
    "    print(f\"  Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    val_accuracy_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # Wrap validation dataset with tqdm for progress bar\n",
    "    val_dataset_tqdm = tqdm(val_dataset, desc=\"Validation Progress\", unit=\"batch\")\n",
    "    for x_batch_val, y_batch_val in val_dataset_tqdm:\n",
    "        # Predictions on validation data\n",
    "        val_logits = student_model(x_batch_val, training=False)\n",
    "        teacher_logits_val = teacher_model(x_batch_val, training=False)\n",
    "        \n",
    "        # Compute validation loss\n",
    "        loss = distillation_loss(y_batch_val, val_logits, teacher_logits_val, temperature)\n",
    "        \n",
    "        # Track validation loss and accuracy\n",
    "        val_loss += loss.numpy()\n",
    "        val_accuracy_metric.update_state(y_batch_val, val_logits)\n",
    "        val_steps += 1\n",
    "        \n",
    "        # Update tqdm description\n",
    "        val_dataset_tqdm.set_postfix(val_loss=loss.numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / val_steps\n",
    "    val_accuracy = val_accuracy_metric.result().numpy()\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Compile the student model\n",
    "student_model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Evaluate the model\n",
    "student_accuracy = student_model.evaluate(x_test, y_test)[1]\n",
    "print(f\"Student Model Accuracy: {student_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb58d4d-d7c6-4517-86d1-3f0a947b46d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
